{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filler scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import pandas as pd\n",
    "\n",
    "scenarios = ['''Imagine that AAA wanted to get BBB’s opinion about a book they just read. After BBB finished the book, AAA asked, “What did you think?” ''',\n",
    "'''Imagine that AAA wanted to get BBB’s opinion about a movie they just watched. After BBB finished the movie, AAA asked, “What did you think?” ''',\n",
    "'''Imagine that AAA wanted to get BBB’s opinion about a restaurant they just visited. After BBB visited the restaurant, AAA asked, “What did you think?” ''',\n",
    "'''Imagine that AAA wanted to get BBB’s opinion about a TV episode they just watched. After BBB finished the episode, AAA asked, “What did you think?” ''',\n",
    "'''Imagine that AAA wanted to get BBB’s opinion about a song they just heard. After BBB finished listening to the song, AAA asked, “What did you think?” ''',\n",
    "'''Imagine that AAA wanted to get BBB’s opinion about a video game they just played. After BBB finished the game, AAA asked, “What did you think?” ''']\n",
    "\n",
    "speakers = [\n",
    "    \"Olivia\", \"Noah\", \"Emma\", \"Liam\", \"Ava\", \"Mason\", \"Isabella\", \"Ethan\", \"Sophia\", \"James\", \"Mia\", \"Benjamin\", \"Charlotte\", \"Lucas\", \"Amelia\", \n",
    "    \"Logan\", \"Harper\", \"Elijah\", \"Evelyn\", \"Oliver\", \"Abigail\", \"Alexander\", \"Emily\", \"Daniel\", \"Madison\", \"Henry\", \"Lily\", \"Jackson\", \"Grace\", \n",
    "    \"Samuel\", \"Chloe\", \"Matthew\", \"Aria\", \"Joseph\", \"Zoey\", \"Michael\", \"Layla\", \"David\", \"Mila\", \"William\", \"Scarlett\", \"Jacob\", \"Ellie\", \n",
    "    \"Sebastian\", \"Nora\", \"Aiden\", \"Sofia\", \"John\", \"Aurora\", \"Ryan\", \"Brooklyn\", \"Nathan\", \"Lucy\", \"Caleb\", \"Riley\", \"Isaac\", \"Hazel\", \n",
    "    \"Jayden\", \"Lily\", \"Christopher\", \"Hannah\", \"Gabriel\", \"Zoe\", \"Anthony\", \"Stella\", \"Andrew\", \"Addison\", \"Joshua\", \"Paisley\", \"Dylan\", \"Penelope\"]\n",
    "\n",
    "\n",
    "genders = [\"woman\", \"man\", \"non-binary person\"]\n",
    "\n",
    "female_names = [\"Sally\", \"Jessica\", \"Sarah\", \"Emily\", \"Hannah\", \"Ellie\"]\n",
    "male_names = [\"Josh\", \"Michael\", \"James\", \"Jacob\", \"Mattem\", \"Chris\"]\n",
    "non_binary_names = [\"Alex\", \"Sam\", \"Charlie\", \"Sage\", \"Taylor\"]\n",
    "\n",
    "pronouns = [\"his\", \"her\", \"their\"]\n",
    "\n",
    "goals = [\n",
    "        \"If BBB wanted to BOTH make AAA feel good AND share PRON honest thoughts, \",\n",
    "        \"If BBB wanted to share PRON honest thoughts, but not necessarily make AAA feel good, \",\n",
    "        \"If BBB wanted to make AAA feel good, but not necessarily share PRON honest thoughts, \",\n",
    "        \"\"\n",
    "]\n",
    "\n",
    "feeling = [\"Here's how BBB actually felt about the book:\", \"Here's how BBB actually felt about the movie:\", \n",
    "           \"Here's how BBB actually felt about the restaurant:\", \"Here's how BBB actually felt about the TV-show:\",\n",
    "           \"Here's how BBB actually felt about the song:\", \"Here's how BBB actually felt about the video game:\"]\n",
    "\n",
    "# states = [\"0 out of 4 hearts\", \"1 out of 4 hearts\", \"2 out of 4 hearts\", \"3 out of 4 hearts\", \"4 out of 4 hearts\"]\n",
    "states = [\"0 out of 3 hearts\", \"1 out of 3 hearts\", \"2 out of 3 hearts\", \"3 out of 3 hearts\"]\n",
    "\n",
    "\n",
    "question = \"What would BBB be most likely to say?\"\n",
    "\n",
    "\n",
    "\n",
    "scenarios_list = []\n",
    "for index, domain in enumerate(scenarios):\n",
    "    for state in states:\n",
    "        for goal in goals:\n",
    "            if goal != \"\":\n",
    "                scenario = \"Scenario:\" + \"\\n\" + domain  + \"\\n\" + \"Rating:\" + \"\\n\" + feeling[index] + \"\\n\" + state + \"\\n\" + \"Question:\" + \"\\n\" + goal + question\n",
    "            else:\n",
    "                scenario = \"Scenario:\" + \"\\n\" + domain  + \"\\n\" + \"Rating:\" + \"\\n\" + feeling[index] + \"\\n\" + state + \"\\n\" + \"Question:\" + \"\\n\" + question\n",
    "\n",
    "            \n",
    "            scenario = scenario.replace(\"AAA\", random.choice(speakers))\n",
    "\n",
    "            chosen_gender = random.choice(genders)\n",
    "\n",
    "            if chosen_gender == \"woman\":\n",
    "                scenario = scenario.replace(\"BBB\", random.choice(female_names))\n",
    "                scenario = scenario.replace(\"PRON\", \"her\")\n",
    "            elif chosen_gender == \"man\":\n",
    "                scenario = scenario.replace(\"BBB\", random.choice(male_names))\n",
    "                scenario = scenario.replace(\"PRON\", \"his\")\n",
    "            elif chosen_gender == \"non-binary person\":\n",
    "                scenario = scenario.replace(\"BBB\", random.choice(non_binary_names))\n",
    "                scenario = scenario.replace(\"PRON\", \"their\")\n",
    "\n",
    "            scenarios_list.append(scenario)\n",
    "\n",
    "df = pd.DataFrame(scenarios_list)\n",
    "df.to_csv(\"../data/filler_scenarios.csv\", index=False, header=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pragmatic free responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = [[\"John\", \"Bob\"], [\"Hailey\", \"Mika\"], [\"Karen\", \"Jenny\"], [\"Kyle\", \"James\"], [\"Sean\", \"Chris\"],\n",
    "                    [\"Lucy\", \"Sarah\"], [\"Bill\", \"Tom\"], [\"Heather\", \"Grace\"], [\"Jake\", \"Kevin\"], [\"Ann\", \"Diana\"],\n",
    "                    [\"George\", \"Henry\"], [\"Nathan\", \"Patrick\"], [\"Wendy\", \"Emma\"], [\"Stephanie\", \"Barbara\"], [\"Oliver\", \"Robert\"],\n",
    "                    [\"Matt\", \"Larry\"], [\"Steven\", \"Zack\"], [\"Fiona\", \"Yvonne\"], [\"Rebecca\", \"Cheryl\"], [\"Victoria\", \"Jasmine\"],\n",
    "                    [\"Albert\", \"Frank\"], [\"Greg\", \"Colin\"], [\"Ed\", \"Peter\"], [\"Molly\", \"Kara\"], [\"Justine\", \"Kelly\"]]\n",
    "\n",
    "domains = {\n",
    "        \"presentation\": {\n",
    "            \"sent_precontext\": \"Imagine that LS just gave a presentation, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about giving presentations, and asked \\\"How was my presentation?\\\"\",\n",
    "            \"sent_context2\": \" SP saw the presentation.\",\n",
    "            \"BB\": \"presentation\",\n",
    "        },\n",
    "        \"cookie\": {\n",
    "            \"sent_precontext\": \"Imagine that LS baked some cookies, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about baking, and asked \\\"How did my cookie taste?\\\"\",\n",
    "            \"sent_context2\": \" SP tasted the cookie.\",\n",
    "            \"BB\": \"cookie\",\n",
    "        },\n",
    "        \"poem\": {\n",
    "            \"sent_precontext\": \"Imagine that LS wrote a poem, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about poems, and asked \\\"How was my poem?\\\"\",\n",
    "            \"sent_context2\": \" SP read the poem.\",\n",
    "            \"BB\": \"poem\",\n",
    "        },\n",
    "        \"cake\": {\n",
    "            \"sent_precontext\": \"Imagine that LS baked a cake, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about baking, and asked \\\"How did my cake taste?\\\"\",\n",
    "            \"sent_context2\": \" SP tasted the cake.\",\n",
    "            \"BB\": \"cake\",\n",
    "        },\n",
    "        \"song\": {\n",
    "            \"sent_precontext\": \"Imagine that LS composed a song, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about composing songs, and asked \\\"How was my song?\\\"\",\n",
    "            \"sent_context2\": \" SP heard the song.\",\n",
    "            \"BB\": \"song\",\n",
    "        },\n",
    "        \"film\": {\n",
    "            \"sent_precontext\": \"Imagine that LS filmed a movie, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about movies, and asked \\\"How was my movie?\\\"\",\n",
    "            \"sent_context2\": \" SP saw the movie.\",\n",
    "            \"BB\": \"movie\",\n",
    "        },\n",
    "        \"solo\": {\n",
    "            \"sent_precontext\": \"Imagine that LS played a cello solo part at a concert, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about playing cello, and asked \\\"How was my solo?\\\"\",\n",
    "            \"sent_context2\": \" SP heard the solo.\",\n",
    "            \"BB\": \"solo\",\n",
    "        },\n",
    "        \"dance\": {\n",
    "            \"sent_precontext\": \"Imagine that LS gave a tap dance performance, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about tap dance, and asked \\\"How was my dance?\\\"\",\n",
    "            \"sent_context2\": \" SP saw the dance.\",\n",
    "            \"BB\": \"dance\",\n",
    "        },\n",
    "        \"painting\": {\n",
    "            \"sent_precontext\": \"Imagine that LS drew a painting, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about paintings, and asked \\\"How was my painting?\\\"\",\n",
    "            \"sent_context2\": \" SP saw the painting.\",\n",
    "            \"BB\": \"painting\",\n",
    "        },\n",
    "        \"monologue\": {\n",
    "            \"sent_precontext\": \"Imagine that LS gave a monologue during a school play, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about giving monologues, and asked \\\"How was my monologue?\\\"\",\n",
    "            \"sent_context2\": \" SP heard the monologue.\",\n",
    "            \"BB\": \"monologue\",\n",
    "        },\n",
    "        \"app\": {\n",
    "            \"sent_precontext\": \"Imagine that LS designed a mobile app, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about mobile apps, and asked \\\"How was my app?\\\"\",\n",
    "            \"sent_context2\": \" SP saw the app.\",\n",
    "            \"BB\": \"app\",\n",
    "        },\n",
    "        \"review\": {\n",
    "            \"sent_precontext\": \"Imagine that LS wrote a review for a book, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about writing reviews, and asked \\\"How was my review?\\\"\",\n",
    "            \"sent_context2\": \" SP read the review.\",\n",
    "            \"BB\": \"review\",\n",
    "        },\n",
    "        \"recital\": {\n",
    "            \"sent_precontext\": \"Imagine that LS had a piano recital, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about playing piano, and asked \\\"How was my performance?\\\"\",\n",
    "            \"sent_context2\": \" SP attended the recital.\",\n",
    "            \"BB\": \"performance\",\n",
    "        },\n",
    "}\n",
    "\n",
    "\n",
    "goals = [\n",
    "        \"If SP wanted to BOTH make LS feel good AND give accurate and informative feedback,\",\n",
    "        \"If SP wanted to give as accurate and informative feedback as possible, but not necessarily make LS feel good,\",\n",
    "        \"If SP wanted to make LS feel good, but not necessarily give informative feedback,\",\n",
    "        \"\"\n",
    "]\n",
    "\n",
    "knowledge = \"but LS didn't know how good it was.\"\n",
    "\n",
    "feeling = \"Here's how SP actually felt about LS's BB:\"\n",
    "\n",
    "question = \"What would SP be most likely to say?\"\n",
    "\n",
    "# states = [\"1 out of 5 hearts\", \"2 out of 5 hearts\", \"3 out of 5 hearts\", \"4 out of 5 hearts\", \"5 out of 5 hearts\"]\n",
    "\n",
    "# states = [\"0 out of 4 hearts\", \"1 out of 4 hearts\", \"2 out of 4 hearts\", \"3 out of 4 hearts\", \"4 out of 4 hearts\"]\n",
    "\n",
    "states = [\"0 out of 3 hearts\", \"1 out of 3 hearts\", \"2 out of 3 hearts\", \"3 out of 3 hearts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_list = []\n",
    "for index, domain in enumerate(domains):\n",
    "        for state in states:\n",
    "            for goal in goals:\n",
    "                if goal != \"\":\n",
    "                    scenario = \"Scenario:\" + \"\\n\" + domains[domain]['sent_precontext'] + knowledge + domains[domain]['sent_context'] + \"\\n\" + \"Rating:\" + \"\\n\" + feeling + \"\\n\" + state + \"\\n\" + \"Question:\" + \"\\n\" + goal + \"\\n\" + question\n",
    "                else:\n",
    "                    scenario = \"Scenario:\" + \"\\n\" + domains[domain]['sent_precontext'] + knowledge + domains[domain]['sent_context'] + \"\\n\" + \"Rating:\" + \"\\n\" + feeling + \"\\n\" + state + \"\\n\" + \"Question:\" + \"\\n\" + question\n",
    "                    \n",
    "                # replace SP with speaker in the speaker list with index\n",
    "                scenario = scenario.replace(\"SP\", speakers[index][0])\n",
    "\n",
    "                # replace LS with speaker in the speaker list with index\n",
    "                scenario = scenario.replace(\"LS\", speakers[index][1])\n",
    "\n",
    "                # replace BB with the BB\n",
    "                scenario = scenario.replace(\"BB\", domains[domain]['BB'])\n",
    "\n",
    "                scenarios_list.append(scenario)\n",
    "\n",
    "# save scenarios_list to a csv file\n",
    "df = pd.DataFrame(scenarios_list)\n",
    "df.to_csv(\"../data/scenarios_utterance_production_free_response_format.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trail data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1 = \"Imagine that Tom saw a prsentation\" + \"\\n\" + \"Here's how Tom felt about the presentation, on a scale of 0 to 3 hearts:\" + \"\\n\" + \"3 out of 3 hearts\" + \"\\n\" + \"Did Tom think the presentation deserved 3 out of 3 hearts?\"\n",
    "scenario_2 = \"Imagine that Tom saw a prsentation\" + \"\\n\" + \"Here's how Tom felt about the presentation, on a scale of 0 to 3 hearts:\" + \"\\n\" + \"2 out of 3 hearts\" + \"\\n\" + \"Did Tom think the presentation deserved 2 out of 3 hearts?\"\n",
    "scenario_3 = \"Imagine that Tom saw a prsentation\" + \"\\n\" + \"Here's how Tom felt about the presentation, on a scale of 0 to 3 hearts:\" + \"\\n\" + \"0 out of 3 hearts\" + \"\\n\" + \"Did Tom think the presentation deserved 0 out of 3 hearts?\"\n",
    "\n",
    "# save scenarios_list to a csv file\n",
    "df = pd.DataFrame([scenario_3, scenario_2, scenario_1])\n",
    "\n",
    "df.to_csv(\"../data/testing_scenarios.csv\", index=False, header=False)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pragmatic scenarios "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers_1 =[[\"John\",\"Bob\",], [\"Hailey\", \"Mika\"], [\"Karen\", \"Jenny\"], [\"Kyle\", \"James\"], [\"Sean\", \"Chris\"],\n",
    "                    [\"Lucy\", \"Sarah\"], [\"Bill\", \"Tom\"], [\"Heather\", \"Grace\"], [\"Jake\", \"Kevin\"], [\"Ann\", \"Diana\"],\n",
    "                    [\"George\", \"Henry\"], [\"Nathan\", \"Patrick\"], [\"Wendy\", \"Emma\"], [\"Stephanie\", \"Barbara\"], [\"Oliver\", \"Robert\"],\n",
    "                    [\"Matt\", \"Larry\"], [\"Steven\", \"Zack\"], [\"Fiona\", \"Yvonne\"], [\"Rebecca\", \"Cheryl\"], [\"Victoria\", \"Jasmine\"],\n",
    "                    [\"Albert\", \"Frank\"], [\"Greg\", \"Colin\"], [\"Ed\", \"Peter\"], [\"Molly\", \"Kara\"], [\"Justine\", \"Kelly\"]]\n",
    "speakers_2 = [[\"Jon\",\"Bob\",\"Kent\"], [\"Haily\", \"Mika\",\"Sherrie\"], [\"Caren\", \"Jen\",\"Pammy\"], [\"Cameron\", \"James\",\"Derek\"], [\"Shawn\", \"Kris\",\"Harry\"],\n",
    "                    [\"Leila\", \"Sara\",\"Joan\"], [\"Bill\", \"Thomas\",\"Lincoln\"], [\"Holly\", \"Gracie\",\"Kristen\"], [\"Jacob\", \"Kevin\",\"Mikhail\"], [\"Annie\", \"Diane\",\"Gina\"],\n",
    "                    [\"Jorge\", \"Henry\",\"Samuel\"], [\"Nathaniel\", \"Phillip\",\"Tyler\"], [\"Willa\", \"Emily\",\"Asha\"], [\"Steph\", \"Bella\",\"Camille\"], [\"Olivier\", \"Russ\",\"Chester\"],\n",
    "                    [\"Maverick\", \"Nolan\",\"Brian\"], [\"Stephan\", \"Zade\",\"Howard\"], [\"Fenna\", \"Kairi\",\"Henrietta\"], [\"Greta\", \"Rachel\",\"Trudy\"], [\"Vicky\", \"Jade\",\"Anais\"],\n",
    "                    [\"Asher\", \"Fred\",\"Cohen\"], [\"Gavin\", \"Caleb\",\"Brody\"], [\"Elias\", \"Phineas\",\"Roman\"], [\"Mila\", \"Cecilia\",\"Daisy\"], [\"Juliet\", \"Paige\",\"Elaine\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers_3 = [\n",
    "    \"Olivia\", \"Noah\", \"Emma\", \"Liam\", \"Ava\", \"Mason\", \"Isabella\", \"Ethan\", \n",
    "    \"Sophia\", \"James\", \"Mia\", \"Benjamin\", \"Charlotte\", \"Lucas\", \"Amelia\", \n",
    "    \"Logan\", \"Harper\", \"Elijah\", \"Evelyn\", \"Oliver\", \"Abigail\", \"Alexander\", \n",
    "    \"Emily\", \"Daniel\", \"Madison\", \"Henry\", \"Lily\", \"Jackson\", \"Grace\", \n",
    "    \"Samuel\", \"Chloe\", \"Matthew\", \"Aria\", \"Joseph\", \"Zoey\", \"Michael\", \n",
    "    \"Layla\", \"David\", \"Mila\", \"William\", \"Scarlett\", \"Jacob\", \"Ellie\", \n",
    "    \"Sebastian\", \"Nora\", \"Aiden\", \"Sofia\", \"John\", \"Aurora\", \"Ryan\", \n",
    "    \"Brooklyn\", \"Nathan\", \"Lucy\", \"Caleb\", \"Riley\", \"Isaac\", \"Hazel\", \n",
    "    \"Jayden\", \"Lily\", \"Christopher\", \"Hannah\", \"Gabriel\", \"Zoe\", \"Anthony\", \n",
    "    \"Stella\", \"Andrew\", \"Addison\", \"Joshua\", \"Paisley\", \"Dylan\", \"Penelope\", \n",
    "    \"Luke\", \"Lillian\", \"Henry\", \"Victoria\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = {\n",
    "    \"states\": [\n",
    "        \"1 heart\",\n",
    "        \"2 hearts\",\n",
    "        \"3 hearts\",\n",
    "        \"4 hearts\",\n",
    "        \"5 hearts\"\n",
    "    ],\n",
    "    \"utterances\": [\n",
    "        'Do you think SP thought the BB was terrible?',\n",
    "        'Do you think SP thought the BB was bad?',\n",
    "        'Do you think SP thought the BB was okay?',\n",
    "        'Do you think SP thought the BB was good?',\n",
    "        'Do you think SP thought the BB was amazing?',\n",
    "        \"Do you think SP thought the BB wasn't terrible?\",\n",
    "        \"Do you think SP thought the BB wasn't bad?\",\n",
    "        \"Do you think SP thought the BB wasn't okay?\",\n",
    "        \"Do you think SP thought the BB wasn't good?\",\n",
    "        \"Do you think SP thought the BB wasn't amazing?\"\n",
    "    ],        \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = {\n",
    "       \"presentation\": {\n",
    "            \"sent_precontext\": \"Imagine that\", \n",
    "            \"sent_context\": \" LS approached SP, who had just seen LS's presentation, and asked \\\"How was my presentation?\\\"\",\n",
    "            \"sent_context2\": \" SP saw a presentation.\",\n",
    "            \"BB\": \"presentation\",\n",
    "\t},\n",
    "\t   \"cookie\": {\n",
    "            \"sent_precontext\": \"Imagine that\", \n",
    "            \"sent_context\": \" LS approached SP, who had just tasted LS's cookie, and asked \\\"How did my cookie taste?\\\"\", \n",
    "            \"sent_context2\": \" SP tasted a cookie.\",\n",
    "            \"BB\": \"cookie\",\n",
    "\t},\n",
    "\t   \"poem\": {\n",
    "            \"sent_precontext\": \"Imagine that\", \n",
    "            \"sent_context\": \" LS approached SP, who had just read LS's poem, and asked \\\"How was my poem?\\\"\", \n",
    "            \"sent_context2\": \" SP read a poem.\",\n",
    "            \"BB\": \"poem\",\n",
    "\t},        \n",
    "\t   \"cake\": {\n",
    "            \"sent_precontext\": \"Imagine that\", \n",
    "            \"sent_context\": \" LS approached SP, who had just tasted LS's cake, and asked \\\"How did my cake taste?\\\"\", \n",
    "            \"sent_context2\": \" SP tasted a cake.\",\n",
    "            \"BB\": \"cake\",\n",
    "\t},\n",
    "\t   \"song\": {\n",
    "            \"sent_precontext\": \"Imagine that\", \n",
    "            \"sent_context\": \" LS approached SP, who had just heard LS's song, and asked \\\"How was my song?\\\"\", \n",
    "            \"sent_context2\": \" SP heard a song.\",\n",
    "            \"BB\": \"song\",\n",
    "\t},\n",
    "\t   \"film\": {\n",
    "            \"sent_precontext\": \"Imagine that\", \n",
    "            \"sent_context\": \" LS approached SP, who had just seen LS's movie, and asked \\\"How was my movie?\\\"\", \n",
    "            \"sent_context2\": \" SP saw a movie.\",\n",
    "            \"BB\": \"movie\",\n",
    "\t},\n",
    "\t   \"solo\": {\n",
    "            \"sent_precontext\": \"Imagine that\", \n",
    "            \"sent_context\": \" LS approached SP, who had just heard LS's solo, and asked \\\"How was my solo?\\\"\", \n",
    "            \"sent_context2\": \" SP heard a cello solo.\",\n",
    "            \"BB\": \"solo\",\n",
    "\t},        \n",
    "\t   \"dance\": {\n",
    "            \"sent_precontext\": \"Imagine that\", \n",
    "            \"sent_context\": \" LS approached SP, who had just seen LS's dance, and asked \\\"How was my dance?\\\"\", \n",
    "            \"sent_context2\": \" SP saw a tap dance performance.\",\n",
    "            \"BB\": \"dance\",\n",
    "\t},   \n",
    "\t   \"painting\": {\n",
    "            \"sent_precontext\": \"Imagine that\", \n",
    "            \"sent_context\": \" LS approached SP, who had just seen LS's painting, and asked \\\"How was my painting?\\\"\", \n",
    "            \"sent_context2\": \" SP saw a painting.\",\n",
    "            \"BB\": \"painting\",\n",
    "\t}, \n",
    "\t   \"monologue\": {\n",
    "            \"sent_precontext\": \"Imagine that\", \n",
    "            \"sent_context\": \" LS approached SP, who had just heard LS's monologue, and asked \\\"How was my monologue?\\\"\", \n",
    "            \"sent_context2\": \" SP heard a monologue in a school play.\",\n",
    "            \"BB\": \"monologue\",\n",
    "\t},\n",
    "\t   \"app\": {\n",
    "            \"sent_precontext\": \"Imagine that\", \n",
    "            \"sent_context\": \" LS approached SP, who looked at LS's mobile app, and asked \\\"How was my app?\\\"\", \n",
    "            \"sent_context2\": \" SP saw a mobile app.\",\n",
    "            \"BB\": \"app\",\n",
    "\t},\n",
    "\t   \"review\": {\n",
    "            \"sent_precontext\": \"Imagine that\", \n",
    "            \"sent_context\": \" LS approached SP, who had just read LS's review, and asked \\\"How was my review?\\\"\", \n",
    "            \"sent_context2\": \" SP read a review for a book.\",\n",
    "            \"BB\": \"review\",\n",
    "\t},\n",
    "\t   \"recital\": {\n",
    "            \"sent_precontext\": \"Imagine that\", \n",
    "            \"sent_context\": \" LS approached SP, who had just attended LS's recital, and asked \\\"How was my recital performance?\\\"\", \n",
    "            \"sent_context2\": \" SP attended a piano recital.\",\n",
    "            \"BB\": \"recital performance\",\n",
    "\t},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeling = \"Here's how SP felt about the BB:\"\n",
    "# prompt =  \"SP's feelings are shown on a scale out of 5 hearts.\"\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "names = speakers_3\n",
    "scenarios_list = []\n",
    "for key in domains:\n",
    "    for heart in sents['states']:\n",
    "        for utterance in sents['utterances']:\n",
    "            scenario = \"Scenario:\" + \"\\n\" +  domains[key]['sent_precontext'] + domains[key]['sent_context2'] + \"\\n\" + feeling  + \"\\n\"  + heart + \"\\n\" + \"Question:\" + \"\\n\" + utterance\n",
    "            # replace SP with speaker with a random name from the speaker list\n",
    "            scenario = scenario.replace(\"SP\", random.choice(names))\n",
    "            # replace BB with the BB\n",
    "            scenario = scenario.replace(\"BB\", domains[key]['BB'])\n",
    "            scenarios_list.append(scenario)\n",
    "\n",
    "# save scenarios_list to a csv file\n",
    "df = pd.DataFrame(scenarios_list)\n",
    "df.to_csv(\"../data/scenarios_literal_semantics.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                   0\n",
       " 0  Scenario:\\nImagine that Penelope saw a present...\n",
       " 1  Scenario:\\nImagine that Nora saw a presentatio...\n",
       " 2  Scenario:\\nImagine that Aurora saw a presentat...\n",
       " 3  Scenario:\\nImagine that Layla saw a presentati...\n",
       " 4  Scenario:\\nImagine that David saw a presentati...,\n",
       " (650, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"Scenario:\\nImagine that Penelope saw a presentation.\\nHere's how Penelope felt about the presentation:\\n1 heart\\nQuestion:\\nDo you think Penelope thought the presentation was terrible?\",\n",
       "  \"Scenario:\\nImagine that Nora saw a presentation.\\nHere's how Nora felt about the presentation:\\n1 heart\\nQuestion:\\nDo you think Nora thought the presentation was bad?\",\n",
       "  \"Scenario:\\nImagine that Aurora saw a presentation.\\nHere's how Aurora felt about the presentation:\\n1 heart\\nQuestion:\\nDo you think Aurora thought the presentation was okay?\",\n",
       "  \"Scenario:\\nImagine that Layla saw a presentation.\\nHere's how Layla felt about the presentation:\\n1 heart\\nQuestion:\\nDo you think Layla thought the presentation was good?\",\n",
       "  \"Scenario:\\nImagine that David saw a presentation.\\nHere's how David felt about the presentation:\\n1 heart\\nQuestion:\\nDo you think David thought the presentation was amazing?\"],\n",
       " 650)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "literal_semantics = pd.read_csv(\"../data/scenarios_literal_semantics.csv\", header=None)\n",
    "\n",
    "# to list\n",
    "literal_semantics = literal_semantics[0].tolist()\n",
    "\n",
    "literal_semantics[:5], len(literal_semantics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = [[\"John\", \"Bob\"], [\"Hailey\", \"Mika\"], [\"Karen\", \"Jenny\"], [\"Kyle\", \"James\"], [\"Sean\", \"Chris\"],\n",
    "                    [\"Lucy\", \"Sarah\"], [\"Bill\", \"Tom\"], [\"Heather\", \"Grace\"], [\"Jake\", \"Kevin\"], [\"Ann\", \"Diana\"],\n",
    "                    [\"George\", \"Henry\"], [\"Nathan\", \"Patrick\"], [\"Wendy\", \"Emma\"], [\"Stephanie\", \"Barbara\"], [\"Oliver\", \"Robert\"],\n",
    "                    [\"Matt\", \"Larry\"], [\"Steven\", \"Zack\"], [\"Fiona\", \"Yvonne\"], [\"Rebecca\", \"Cheryl\"], [\"Victoria\", \"Jasmine\"],\n",
    "                    [\"Albert\", \"Frank\"], [\"Greg\", \"Colin\"], [\"Ed\", \"Peter\"], [\"Molly\", \"Kara\"], [\"Justine\", \"Kelly\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "goals = [\n",
    "        \"If SP wanted to BOTH make LS feel good AND give accurate and informative feedback,\",\n",
    "        \"If SP wanted to give as accurate and informative feedback as possible, but not necessarily make LS feel good,\",\n",
    "        \"If SP wanted to make LS feel good, but not necessarily give informative feedback,\",\n",
    "        \"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = {\n",
    "        \"presentation\": {\n",
    "            \"sent_precontext\": \"Imagine that LS just gave a presentation, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about giving presentations, and asked \\\"How was my presentation?\\\"\",\n",
    "            \"sent_context2\": \" SP saw the presentation.\",\n",
    "            \"BB\": \"presentation\",\n",
    "        },\n",
    "        \"cookie\": {\n",
    "            \"sent_precontext\": \"Imagine that LS baked some cookies, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about baking, and asked \\\"How did my cookie taste?\\\"\",\n",
    "            \"sent_context2\": \" SP tasted the cookie.\",\n",
    "            \"BB\": \"cookie\",\n",
    "        },\n",
    "        \"poem\": {\n",
    "            \"sent_precontext\": \"Imagine that LS wrote a poem, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about poems, and asked \\\"How was my poem?\\\"\",\n",
    "            \"sent_context2\": \" SP read the poem.\",\n",
    "            \"BB\": \"poem\",\n",
    "        },\n",
    "        \"cake\": {\n",
    "            \"sent_precontext\": \"Imagine that LS baked a cake, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about baking, and asked \\\"How did my cake taste?\\\"\",\n",
    "            \"sent_context2\": \" SP tasted the cake.\",\n",
    "            \"BB\": \"cake\",\n",
    "        },\n",
    "        \"song\": {\n",
    "            \"sent_precontext\": \"Imagine that LS composed a song, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about composing songs, and asked \\\"How was my song?\\\"\",\n",
    "            \"sent_context2\": \" SP heard the song.\",\n",
    "            \"BB\": \"song\",\n",
    "        },\n",
    "        \"film\": {\n",
    "            \"sent_precontext\": \"Imagine that LS filmed a movie, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about movies, and asked \\\"How was my movie?\\\"\",\n",
    "            \"sent_context2\": \" SP saw the movie.\",\n",
    "            \"BB\": \"movie\",\n",
    "        },\n",
    "        \"solo\": {\n",
    "            \"sent_precontext\": \"Imagine that LS played a cello solo part at a concert, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about playing cello, and asked \\\"How was my solo?\\\"\",\n",
    "            \"sent_context2\": \" SP heard the solo.\",\n",
    "            \"BB\": \"solo\",\n",
    "        },\n",
    "        \"dance\": {\n",
    "            \"sent_precontext\": \"Imagine that LS gave a tap dance performance, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about tap dance, and asked \\\"How was my dance?\\\"\",\n",
    "            \"sent_context2\": \" SP saw the dance.\",\n",
    "            \"BB\": \"dance\",\n",
    "        },\n",
    "        \"painting\": {\n",
    "            \"sent_precontext\": \"Imagine that LS drew a painting, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about paintings, and asked \\\"How was my painting?\\\"\",\n",
    "            \"sent_context2\": \" SP saw the painting.\",\n",
    "            \"BB\": \"painting\",\n",
    "        },\n",
    "        \"monologue\": {\n",
    "            \"sent_precontext\": \"Imagine that LS gave a monologue during a school play, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about giving monologues, and asked \\\"How was my monologue?\\\"\",\n",
    "            \"sent_context2\": \" SP heard the monologue.\",\n",
    "            \"BB\": \"monologue\",\n",
    "        },\n",
    "        \"app\": {\n",
    "            \"sent_precontext\": \"Imagine that LS designed a mobile app, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about mobile apps, and asked \\\"How was my app?\\\"\",\n",
    "            \"sent_context2\": \" SP saw the app.\",\n",
    "            \"BB\": \"app\",\n",
    "        },\n",
    "        \"review\": {\n",
    "            \"sent_precontext\": \"Imagine that LS wrote a review for a book, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about writing reviews, and asked \\\"How was my review?\\\"\",\n",
    "            \"sent_context2\": \" SP read the review.\",\n",
    "            \"BB\": \"review\",\n",
    "        },\n",
    "        \"recital\": {\n",
    "            \"sent_precontext\": \"Imagine that LS had a piano recital, \",\n",
    "            \"sent_context\": \" LS approached SP, who knows a lot about playing piano, and asked \\\"How was my performance?\\\"\",\n",
    "            \"sent_context2\": \" SP attended the recital.\",\n",
    "            \"BB\": \"performance\",\n",
    "        },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['terrible', 'bad', 'okay', 'good', 'amazing']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knowledge = \"but LS didn't know how good it was.\"\n",
    "\n",
    "feeling = \"Here's how SP actually felt about LS's BB:\"\n",
    "\n",
    "# feeling_2 = \"Here's SP's rating of LS's BB:\"\n",
    "\n",
    "states = [\"0 out of 3 hearts\", \"1 out of 3 hearts\", \"2 out of 3 hearts\", \"3 out of 3 hearts\"]\n",
    "\n",
    "# states_2 = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "\n",
    "question = \"What would SP be most likely to say?\"\n",
    "\n",
    "# ['terrible', 'bad', 'okay', 'good', 'amazing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_options = [\n",
    "        \"1) It was terrible.\\n\", \n",
    "        \"2) It was bad.\\n\", \n",
    "        \"3) It was good.\\n\", \n",
    "        \"4) It was amazing.\\n\",\n",
    "        \"5) It wasn't terrible.\\n\", \n",
    "        \"6) It wasn't bad.\\n\", \n",
    "        \"7) It wasn't good.\\n\", \n",
    "        \"8) It wasn't amazing.\\n\"\n",
    "    ]\n",
    "\n",
    "\n",
    "scenarios_list = []\n",
    "for index, domain in enumerate(domains):\n",
    "        for state in states:\n",
    "            for goal in goals:\n",
    "                if goal != \"\":\n",
    "                    scenario = \"Scenario:\" + \"\\n\" + domains[domain]['sent_precontext'] + knowledge + domains[domain]['sent_context'] + \"\\n\" + feeling + \"\\n\" + state + \"\\n\" + \"Question:\" + \"\\n\" + goal + \"\\n\" + question + \"\\n\" + \"Options:\" + \"\\n\"\n",
    "                else:\n",
    "                     scenario = \"Scenario:\" + \"\\n\" + domains[domain]['sent_precontext'] + knowledge + domains[domain]['sent_context'] + \"\\n\" + feeling + \"\\n\" + state + \"\\n\" + \"Question:\" + \"\\n\" + question + \"\\n\" + \"Options:\" + \"\\n\"\n",
    "                for option in answer_options:\n",
    "                    scenario += option\n",
    "\n",
    "                # replace SP with speaker in the speaker list with index\n",
    "                scenario = scenario.replace(\"SP\", speakers[index][0])\n",
    "\n",
    "                # replace LS with speaker in the speaker list with index\n",
    "                scenario = scenario.replace(\"LS\", speakers[index][1])\n",
    "\n",
    "                # replace BB with the BB\n",
    "                scenario = scenario.replace(\"BB\", domains[domain]['BB'])\n",
    "\n",
    "                scenarios_list.append(scenario)\n",
    "\n",
    "# save scenarios_list to a csv file\n",
    "df = pd.DataFrame(scenarios_list)\n",
    "df.to_csv(\"../data/scenarios_utterance_production_multi_choice_format.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goals = [\n",
    "        \"both: If SP wanted to BOTH make LS feel good AND give accurate and informative feedback,\",\n",
    "        \"informative: If SP wanted to give as accurate and informative feedback as possible, but not necessarily make LS feel good,\",\n",
    "        \"social: If SP wanted to make LS feel good, but not necessarily give informative feedback,\",\n",
    "        \"default:\"\n",
    "]\n",
    "\n",
    "scenarios_list = []\n",
    "for index, domain in enumerate(domains):\n",
    "        for state in states:\n",
    "            for goal in goals:\n",
    "                scenario = \"Scenario:\" + \"\\n\" + domains[domain]['sent_precontext'] + knowledge + domains[domain]['sent_context'] + \"\\n\" + feeling + \"\\n\" + state + \"\\n\" + \"Question:\" + \"\\n\" + goal + \"\\n\" + question + \"\\n\" + \"Options:\" + \"\\n\"\n",
    "\n",
    "                for option in answer_options:\n",
    "                    scenario += option\n",
    "\n",
    "                # replace SP with speaker in the speaker list with index\n",
    "                scenario = scenario.replace(\"SP\", speakers[index][0])\n",
    "\n",
    "                # replace LS with speaker in the speaker list with index\n",
    "                scenario = scenario.replace(\"LS\", speakers[index][1])\n",
    "\n",
    "                # replace BB with the BB\n",
    "                scenario = scenario.replace(\"BB\", domains[domain]['BB'])\n",
    "\n",
    "                scenarios_list.append(scenario)\n",
    "\n",
    "# save scenarios_list to a csv file\n",
    "df = pd.DataFrame(scenarios_list)\n",
    "df.to_csv(\"../data/scenarios_utterance_production_for_evaluation.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### group of friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains_group_friends = {\n",
    "        \"presentation\": {\n",
    "            \"sent_precontext\": \"Imagine that LS just gave a presentation, \",\n",
    "            \"sent_context\": \" LS approached a group of NUM friends who know a lot about giving presentations, and asked \\\"How was my presentation?\\\"\",\n",
    "            \"extra_context\": \"Each of the friends has distinct personalities and relationships with LS.\",\n",
    "            \"sent_context2\": \" SP saw the presentation.\",\n",
    "            \"BB\": \"presentation\",\n",
    "        },\n",
    "        \"cookie\": {\n",
    "            \"sent_precontext\": \"Imagine that LS baked some cookies, \",\n",
    "            \"sent_context\": \" LS approached a group of NUM friends who know a lot about baking, and asked \\\"How did my cookie taste?\\\"\",\n",
    "            \"extra_context\": \"Each of the friends has distinct personalities and relationships with LS.\",\n",
    "            \"sent_context2\": \" SP tasted the cookie.\",\n",
    "            \"BB\": \"cookie\",\n",
    "        },\n",
    "        \"poem\": {\n",
    "            \"sent_precontext\": \"Imagine that LS wrote a poem, \",\n",
    "            \"sent_context\": \" LS approached a group of NUM friends who know a lot about poems, and asked \\\"How was my poem?\\\"\",\n",
    "            \"extra_context\": \"Each of the friends has distinct personalities and relationships with LS.\",\n",
    "            \"sent_context2\": \" SP read the poem.\",\n",
    "            \"BB\": \"poem\",\n",
    "        },\n",
    "        \"cake\": {\n",
    "            \"sent_precontext\": \"Imagine that LS baked a cake, \",\n",
    "            \"sent_context\": \" LS approached a group of NUM friends who know a lot about baking, and asked \\\"How did my cake taste?\\\"\",\n",
    "            \"extra_context\": \"Each of the friends has distinct personalities and relationships with LS.\",\n",
    "            \"sent_context2\": \" SP tasted the cake.\",\n",
    "            \"BB\": \"cake\",\n",
    "        },\n",
    "        \"song\": {\n",
    "            \"sent_precontext\": \"Imagine that LS composed a song, \",\n",
    "            \"sent_context\": \" LS approached a group of NUM friends who know a lot about composing songs, and asked \\\"How was my song?\\\"\",\n",
    "            \"extra_context\": \"Each of the friends has distinct personalities and relationships with LS.\",\n",
    "            \"sent_context2\": \" SP heard the song.\",\n",
    "            \"BB\": \"song\",\n",
    "        },\n",
    "        \"film\": {\n",
    "            \"sent_precontext\": \"Imagine that LS filmed a movie, \",\n",
    "            \"sent_context\": \" LS approached a group of NUM friends who know a lot about movies, and asked \\\"How was my movie?\\\"\",\n",
    "            \"extra_context\": \"Each of the friends has distinct personalities and relationships with LS.\",\n",
    "            \"sent_context2\": \" SP saw the movie.\",\n",
    "            \"BB\": \"movie\",\n",
    "        },\n",
    "        \"solo\": {\n",
    "            \"sent_precontext\": \"Imagine that LS played a cello solo part at a concert, \",\n",
    "            \"sent_context\": \" LS approached a group of NUM friends who know a lot about playing cello, and asked \\\"How was my solo?\\\"\",\n",
    "            \"extra_context\": \"Each of the friends has distinct personalities and relationships with LS.\",\n",
    "            \"sent_context2\": \" SP heard the solo.\",\n",
    "            \"BB\": \"solo\",\n",
    "        },\n",
    "        \"dance\": {\n",
    "            \"sent_precontext\": \"Imagine that LS gave a tap dance performance, \",\n",
    "            \"sent_context\": \" LS approached a group of NUM friends who know a lot about tap dance, and asked \\\"How was my dance?\\\"\",\n",
    "            \"extra_context\": \"Each of the friends has distinct personalities and relationships with LS.\",\n",
    "            \"sent_context2\": \" SP saw the dance.\",\n",
    "            \"BB\": \"dance\",\n",
    "        },\n",
    "        \"painting\": {\n",
    "            \"sent_precontext\": \"Imagine that LS drew a painting, \",\n",
    "            \"sent_context\": \" LS approached a group of NUM friends who know a lot about paintings, and asked \\\"How was my painting?\\\"\",\n",
    "            \"extra_context\": \"Each of the friends has distinct personalities and relationships with LS.\",\n",
    "            \"sent_context2\": \" SP saw the painting.\",\n",
    "            \"BB\": \"painting\",\n",
    "        },\n",
    "        \"monologue\": {\n",
    "            \"sent_precontext\": \"Imagine that LS gave a monologue during a school play, \",\n",
    "            \"sent_context\": \" LS approached a group of NUM friends who know a lot about giving monologues, and asked \\\"How was my monologue?\\\"\",\n",
    "            \"extra_context\": \"Each of the friends has distinct personalities and relationships with LS.\",\n",
    "            \"sent_context2\": \" SP heard the monologue.\",\n",
    "            \"BB\": \"monologue\",\n",
    "        },\n",
    "        \"app\": {\n",
    "            \"sent_precontext\": \"Imagine that LS designed a mobile app, \",\n",
    "            \"sent_context\": \" LS approached a group of NUM friends who know a lot about mobile apps, and asked \\\"How was my app?\\\"\",\n",
    "            \"extra_context\": \"Each of the friends has distinct personalities and relationships with LS.\",\n",
    "            \"sent_context2\": \" SP saw the app.\",\n",
    "            \"BB\": \"app\",\n",
    "        },\n",
    "        \"review\": {\n",
    "            \"sent_precontext\": \"Imagine that LS wrote a review for a book, \",\n",
    "            \"sent_context\": \" LS approached a group of NUM friends who know a lot about writing reviews, and asked \\\"How was my review?\\\"\",\n",
    "            \"extra_context\": \"Each of the friends has distinct personalities and relationships with LS.\",\n",
    "            \"sent_context2\": \" SP read the review.\",\n",
    "            \"BB\": \"review\",\n",
    "        },\n",
    "        \"recital\": {\n",
    "            \"sent_precontext\": \"Imagine that LS had a piano recital, \",\n",
    "            \"sent_context\": \" LS approached a group of NUM friends who know a lot about playing piano, and asked \\\"How was my performance?\\\"\",\n",
    "            \"extra_context\": \"Each of the friends has distinct personalities and relationships with LS.\",\n",
    "            \"sent_context2\": \" SP attended the recital.\",\n",
    "            \"BB\": \"performance\",\n",
    "        },\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "group_feeling = \"All of LS's friends felt the same and here is how they felt about LS's BB:\"\n",
    "\n",
    "group_goals = [\n",
    "        \"If all NUM friends wanted to BOTH make LS feel good AND give accurate and informative feedback,\",\n",
    "        \"If all NUM friends wanted to give as accurate and informative feedback as possible, but not necessarily make LS feel good,\",\n",
    "        \"If all NUM friends wanted to make LS feel good, but not necessarily give informative feedback,\",\n",
    "        \"\"\n",
    "]\n",
    "\n",
    "group_question = \"What would they be most likely to say? Please give individual responses for each of LS's friends - NUM responses in total, reflecting the distribution of likely responses.\"\n",
    "# group_question = \"What would they be most likely to say? Please give individual responses for each of LS's friends - NUM responses in total.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nImagine that Justine wrote a review for a book, but Justine didn't know how good it was. Justine approached a group of 30 friends who know a lot about writing reviews, and asked, “How was my review?”\\nEach of the friends has distinct personalities and relationships with Justine.\\nAll of Justine's friends felt the same and here is how they felt about Justine's review:\\n1 out of 5 hearts\\n\\nQuestion:\\nIf all 30 friends wanted to make Justine feel good, but not necessarily give informative feedback, what would they be most likely to say? Please give individual responses for each of Justine's friends - 30 responses in total, reflecting the distribution of likely responses.\\n\\nPossible answers:\\nIt [was, wasn't] [terrible, bad, okay, good, amazing]\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a sample scenario:\n",
    "\n",
    "\"\"\"\n",
    "Imagine that Justine wrote a review for a book, but Justine didn't know how good it was. Justine approached a group of 30 friends who know a lot about writing reviews, and asked, “How was my review?”\n",
    "Each of the friends has distinct personalities and relationships with Justine.\n",
    "All of Justine's friends felt the same and here is how they felt about Justine's review:\n",
    "1 out of 5 hearts\n",
    "\n",
    "Question:\n",
    "If all 30 friends wanted to make Justine feel good, but not necessarily give informative feedback, what would they be most likely to say? Please give individual responses for each of Justine's friends - 30 responses in total, reflecting the distribution of likely responses.\n",
    "\n",
    "Possible answers:\n",
    "It [was, wasn't] [terrible, bad, okay, good, amazing]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_options = [\n",
    "        \"1) It was terrible.\\n\", \n",
    "        \"2) It was bad.\\n\", \n",
    "        \"3) It was good.\\n\", \n",
    "        \"4) It was amazing.\\n\",\n",
    "        \"5) It wasn't terrible.\\n\", \n",
    "        \"6) It wasn't bad.\\n\", \n",
    "        \"7) It wasn't good.\\n\", \n",
    "        \"8) It wasn't amazing.\\n\"\n",
    "    ]\n",
    "\n",
    "num = \"30\"\n",
    "\n",
    "scenarios_list = []\n",
    "for index, domain in enumerate(domains_group_friends):\n",
    "        for state in states:\n",
    "            for goal in group_goals:\n",
    "                if goal != \"\":\n",
    "                    scenario = \"Scenario:\" + \"\\n\" + domains_group_friends[domain]['sent_precontext'] + knowledge + domains_group_friends[domain]['sent_context'] + \"\\n\" + domains_group_friends[domain]['extra_context'] + \"\\n\" + group_feeling + \"\\n\" + state + \"\\n\" + \"Question:\" + \"\\n\" + goal + \"\\n\" + group_question + \"\\n\" + \"Options:\" + \"\\n\"\n",
    "                else:\n",
    "                     scenario = \"Scenario:\" + \"\\n\" + domains_group_friends[domain]['sent_precontext'] + knowledge + domains_group_friends[domain]['sent_context'] + \"\\n\" + domains_group_friends[domain]['extra_context'] + \"\\n\" + group_feeling + \"\\n\" + state + \"\\n\" + \"Question:\" + \"\\n\" + group_question + \"\\n\" + \"Options:\" + \"\\n\"\n",
    "                for option in answer_options:\n",
    "                    scenario += option\n",
    "\n",
    "                # replace SP with speaker in the speaker list with index\n",
    "                scenario = scenario.replace(\"NUM\", num)\n",
    "\n",
    "                # replace LS with speaker in the speaker list with index\n",
    "                scenario = scenario.replace(\"LS\", speakers[index][1])\n",
    "\n",
    "                # replace BB with the BB\n",
    "                scenario = scenario.replace(\"BB\", domains[domain]['BB'])\n",
    "\n",
    "                scenarios_list.append(scenario)\n",
    "\n",
    "# save scenarios_list to a csv file\n",
    "df = pd.DataFrame(scenarios_list)\n",
    "df.to_csv(\"../data/scenarios_utterance_production_multi_choice_format_group_friends.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### persona prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "races = [\"white\", \"Black\", \"Asian\", \"Hispanic\", \"American-Indian\"]\n",
    "genders = [\"woman\", \"man\", \"non-binary person\"]\n",
    "cities = [\"New York\", \"Chicago\", \"San Francisco\", \"Boston\", \"Houston\"]\n",
    "numbers = [\"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\"]\n",
    "occupations = [\"a critic\", \"an expert\", \"a teacher\", \"a friend\", \"a colleague\", \"an acquaintance\"]\n",
    "\n",
    "\n",
    "female_names = [\"Sally\", \"Jessica\", \"Sarah\", \"Emily\", \"Hannah\", \"Ellie\"]\n",
    "male_names = [\"Josh\", \"Michael\", \"James\", \"Jacob\", \"Mattem\", \"Chris\"]\n",
    "non_binary_names = [\"Alex\", \"Sam\", \"Charlie\", \"Sage\", \"Taylor\"]\n",
    "\n",
    "knowledge = \"but LS didn't know how good it was.\"\n",
    "\n",
    "feeling = \"Here's how SP actually felt about LS's BB:\"\n",
    "\n",
    "states = [\"0 out of 3 hearts\", \"1 out of 3 hearts\", \"2 out of 3 hearts\", \"3 out of 3 hearts\"]\n",
    "\n",
    "question = \"What would SP be most likely to say?\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains_persona = {\n",
    "        \"presentation\": {\n",
    "            \"sent_precontext\": \"Imagine that LS just gave a presentation, \",\n",
    "            \"sent_context\": \" LS approached SP , a RACE GENDER from CITY, who has NUMBER years of experience as OCCUPATION in the field and knows a lot about giving presentations. LS asked \\\"How was my presentation?\\\"\",\n",
    "            \"sent_context2\": \" SP saw the presentation.\",\n",
    "            \"BB\": \"presentation\",\n",
    "        },\n",
    "        \"cookie\": {\n",
    "            \"sent_precontext\": \"Imagine that LS baked some cookies, \",\n",
    "            \"sent_context\": \" LS approached SP, a RACE GENDER from CITY, who has NUMBER years of experience as OCCUPATION in the field and knows a lot about baking. LS asked \\\"How did my cookie taste?\\\"\",\n",
    "            \"sent_context2\": \" SP tasted the cookie.\",\n",
    "            \"BB\": \"cookie\",\n",
    "        },\n",
    "        \"poem\": {\n",
    "            \"sent_precontext\": \"Imagine that LS wrote a poem, \",\n",
    "            \"sent_context\": \" LS approached SP, a RACE GENDER from CITY, who has NUMBER years of experience as OCCUPATION in the field and knows a lot about poems. LS asked \\\"How was my poem?\\\"\",\n",
    "            \"sent_context2\": \" SP read the poem.\",\n",
    "            \"BB\": \"poem\",\n",
    "        },\n",
    "        \"cake\": {\n",
    "            \"sent_precontext\": \"Imagine that LS baked a cake, \",\n",
    "            \"sent_context\": \" LS approached SP, a RACE GENDER from CITY, who has NUMBER years of experience as OCCUPATION in the field and knows a lot about baking. LS asked \\\"How did my cake taste?\\\"\",\n",
    "            \"sent_context2\": \" SP tasted the cake.\",\n",
    "            \"BB\": \"cake\",\n",
    "        },\n",
    "        \"song\": {\n",
    "            \"sent_precontext\": \"Imagine that LS composed a song, \",\n",
    "            \"sent_context\": \" LS approached SP, a RACE GENDER from CITY, who has NUMBER years of experience as OCCUPATION in the field and knows a lot about composing songs. LS asked \\\"How was my song?\\\"\",\n",
    "            \"sent_context2\": \" SP heard the song.\",\n",
    "            \"BB\": \"song\",\n",
    "        },\n",
    "        \"film\": {\n",
    "            \"sent_precontext\": \"Imagine that LS filmed a movie, \",\n",
    "            \"sent_context\": \" LS approached SP, a RACE GENDER from CITY, who has NUMBER years of experience as OCCUPATION in the field and knows a lot about movies. LS asked \\\"How was my movie?\\\"\",\n",
    "            \"sent_context2\": \" SP saw the movie.\",\n",
    "            \"BB\": \"movie\",\n",
    "        },\n",
    "        \"solo\": {\n",
    "            \"sent_precontext\": \"Imagine that LS played a cello solo part at a concert, \",\n",
    "            \"sent_context\": \" LS approached SP, a RACE GENDER from CITY, who has NUMBER years of experience as OCCUPATION in the field and knows a lot about playing cello. LS asked \\\"How was my solo?\\\"\",\n",
    "            \"sent_context2\": \" SP heard the solo.\",\n",
    "            \"BB\": \"solo\",\n",
    "        },\n",
    "        \"dance\": {\n",
    "            \"sent_precontext\": \"Imagine that LS gave a tap dance performance, \",\n",
    "            \"sent_context\": \" LS approached SP, a RACE GENDER from CITY, who has NUMBER years of experience as OCCUPATION in the field and knows a lot about tap dance. LS asked \\\"How was my dance?\\\"\",\n",
    "            \"sent_context2\": \" SP saw the dance.\",\n",
    "            \"BB\": \"dance\",\n",
    "        },\n",
    "        \"painting\": {\n",
    "            \"sent_precontext\": \"Imagine that LS drew a painting, \",\n",
    "            \"sent_context\": \" LS approached SP, a RACE GENDER from CITY, who has NUMBER years of experience as OCCUPATION in the field and knows a lot about paintings. LS asked \\\"How was my painting?\\\"\",\n",
    "            \"sent_context2\": \" SP saw the painting.\",\n",
    "            \"BB\": \"painting\",\n",
    "        },\n",
    "        \"monologue\": {\n",
    "            \"sent_precontext\": \"Imagine that LS gave a monologue during a school play, \",\n",
    "            \"sent_context\": \" LS approached SP, a RACE GENDER from CITY, who has NUMBER years of experience as OCCUPATION in the field and knows a lot about giving monologues. LS asked \\\"How was my monologue?\\\"\",\n",
    "            \"sent_context2\": \" SP heard the monologue.\",\n",
    "            \"BB\": \"monologue\",\n",
    "        },\n",
    "        \"app\": {\n",
    "            \"sent_precontext\": \"Imagine that LS designed a mobile app, \",\n",
    "            \"sent_context\": \" LS approached SP, a RACE GENDER from CITY, who has NUMBER years of experience as OCCUPATION in the field and knows a lot about mobile apps. LS asked \\\"How was my app?\\\"\",\n",
    "            \"sent_context2\": \" SP saw the app.\",\n",
    "            \"BB\": \"app\",\n",
    "        },\n",
    "        \"review\": {\n",
    "            \"sent_precontext\": \"Imagine that LS wrote a review for a book, \",\n",
    "            \"sent_context\": \" LS approached SP, a RACE GENDER from CITY, who has NUMBER years of experience as OCCUPATION in the field and knows a lot about writing reviews. LS asked \\\"How was my review?\\\"\",\n",
    "            \"sent_context2\": \" SP read the review.\",\n",
    "            \"BB\": \"review\",\n",
    "        },\n",
    "        \"recital\": {\n",
    "            \"sent_precontext\": \"Imagine that LS had a piano recital, \",\n",
    "            \"sent_context\": \" LS approached SP, a RACE GENDER from CITY, who has NUMBER years of experience as OCCUPATION in the field and knows a lot about playing piano. LS asked \\\"How was my performance?\\\"\",\n",
    "            \"sent_context2\": \" SP attended the recital.\",\n",
    "            \"BB\": \"performance\",\n",
    "        },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "answer_options = [\n",
    "        \"1) It was terrible.\\n\", \n",
    "        \"2) It was bad.\\n\", \n",
    "        \"3) It was good.\\n\", \n",
    "        \"4) It was amazing.\\n\",\n",
    "        \"5) It wasn't terrible.\\n\", \n",
    "        \"6) It wasn't bad.\\n\", \n",
    "        \"7) It wasn't good.\\n\", \n",
    "        \"8) It wasn't amazing.\\n\"\n",
    "    ]\n",
    "\n",
    "num_completions = 30\n",
    "\n",
    "scenarios_list = []\n",
    "for index, domain in enumerate(domains_persona):\n",
    "        for state in states:\n",
    "            for goal in goals:\n",
    "                if goal != \"\":\n",
    "                    base_scenario = \"Scenario:\" + \"\\n\" + domains_persona[domain]['sent_precontext'] + knowledge + domains_persona[domain]['sent_context'] + \"\\n\" + feeling + \"\\n\" + state + \"\\n\" + \"Question:\" + \"\\n\" + goal + \"\\n\" + question + \"\\n\" + \"Options:\" + \"\\n\"\n",
    "                else:\n",
    "                     base_scenario = \"Scenario:\" + \"\\n\" + domains_persona[domain]['sent_precontext'] + knowledge + domains_persona[domain]['sent_context'] + \"\\n\" + feeling + \"\\n\" + state + \"\\n\" + \"Question:\" + \"\\n\" + question + \"\\n\" + \"Options:\" + \"\\n\"\n",
    "                for option in answer_options:\n",
    "                    base_scenario += option\n",
    "\n",
    "                for _ in range(num_completions):\n",
    "                    scenario = base_scenario\n",
    "\n",
    "                    # replace SP with speaker in the speaker list with index\n",
    "                    scenario = scenario.replace(\"LS\", speakers[index][0])\n",
    "\n",
    "                    # replace RACE with race from the races list above, random sample from the list races\n",
    "                    scenario = scenario.replace(\"RACE\", random.choice(races))\n",
    "\n",
    "                    # replace GENDER with from the genders list above, random sample from the list\n",
    "                    chosen_gender = random.choice(genders)\n",
    "                    scenario = scenario.replace(\"GENDER\", chosen_gender)\n",
    "\n",
    "                    # replace SP with female_names if GENDER == woman, replace SP with male_name if GENDER == man, replace SP with non_binary names if GENDER == non-binary person\n",
    "                    if chosen_gender == \"woman\":\n",
    "                        scenario = scenario.replace(\"SP\", random.choice(female_names))\n",
    "                    elif chosen_gender == \"man\":\n",
    "                        scenario = scenario.replace(\"SP\", random.choice(male_names))\n",
    "                    elif chosen_gender == \"non-binary person\":\n",
    "                        scenario = scenario.replace(\"SP\", random.choice(non_binary_names))\n",
    "\n",
    "                    # replace CITY with from the cities list above, random sample from the list\n",
    "                    scenario = scenario.replace(\"CITY\", random.choice(cities))\n",
    "\n",
    "                    # replace NUMBER with from the numbers list above, random sample from the list\n",
    "                    scenario = scenario.replace(\"NUMBER\", random.choice(numbers))\n",
    "\n",
    "                    # replace OCCUPATION with from the occupations list above, random sample from the list\n",
    "                    scenario = scenario.replace(\"OCCUPATION\", random.choice(occupations))\n",
    "\n",
    "                    # replace BB with the BB\n",
    "                    scenario = scenario.replace(\"BB\", domains[domain]['BB'])\n",
    "\n",
    "                    scenarios_list.append(scenario)\n",
    "\n",
    "# save scenarios_list to a csv file\n",
    "df = pd.DataFrame(scenarios_list)\n",
    "df.to_csv(\"../data/scenarios_utterance_production_multi_choice_format_persona.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## appendix code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_options = [\n",
    "        \"1) It was terrible.\\n\", \n",
    "        \"2) It was bad.\\n\", \n",
    "        \"3) It was okay.\\n\", \n",
    "        \"4) It was good.\\n\", \n",
    "        \"5) It was amazing.\\n\",\n",
    "        \"6) It wasn't terrible.\\n\", \n",
    "        \"7) It wasn't bad.\\n\", \n",
    "        \"8) It wasn't okay.\\n\", \n",
    "        \"9) It wasn't good.\\n\", \n",
    "        \"10) It wasn't amazing.\\n\"\n",
    "    ]\n",
    "\n",
    "\n",
    "scenarios_list = []\n",
    "for index, domain in enumerate(domains):\n",
    "        for state in states:\n",
    "            for goal in goals:\n",
    "                scenario = \"Scenario:\" + \"\\n\" + domains[domain]['sent_precontext'] + knowledge + domains[domain]['sent_context'] + \"\\n\" + feeling + \"\\n\" + state + \"\\n\" + \"Question:\" + \"\\n\" + goal + \"\\n\" + question + \"\\n\" + \"Options:\" + \"\\n\"\n",
    "\n",
    "                for option in answer_options:\n",
    "                    scenario += option\n",
    "\n",
    "                # for the scenario, randomly sample 10 times from the speaker like\n",
    "                for i in range(10):\n",
    "                    # replace SP with speaker in the speaker list with index\n",
    "                    scenario = scenario.replace(\"SP\", random.choice(names))\n",
    "\n",
    "                    # replace LS with speaker in the speaker list with index\n",
    "                    scenario = scenario.replace(\"LS\", random.choice(names))\n",
    "\n",
    "                    # replace BB with the BB\n",
    "                    scenario = scenario.replace(\"BB\", domains[domain]['BB'])\n",
    "\n",
    "                    scenarios_list.append(scenario)\n",
    "                     \n",
    "                # # replace SP with speaker in the speaker list with index\n",
    "                # scenario = scenario.replace(\"SP\", speakers[index][0])\n",
    "\n",
    "                # # replace LS with speaker in the speaker list with index\n",
    "                # scenario = scenario.replace(\"LS\", speakers[index][1])\n",
    "\n",
    "                # # replace BB with the BB\n",
    "                # scenario = scenario.replace(\"BB\", domains[domain]['BB'])\n",
    "\n",
    "                # scenarios_list.append(scenario)\n",
    "\n",
    "# save scenarios_list to a csv file\n",
    "df = pd.DataFrame(scenarios_list)\n",
    "df.to_csv(\"../data/scenarios_utterance_production_multi_choice_format_10_different_names.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_options = [\n",
    "        \"1) It was terrible.\\n\", \n",
    "        \"2) It was bad.\\n\", \n",
    "        \"3) It was okay.\\n\", \n",
    "        \"4) It was good.\\n\", \n",
    "        \"5) It was amazing.\\n\",\n",
    "        \"6) It wasn't terrible.\\n\", \n",
    "        \"7) It wasn't bad.\\n\", \n",
    "        \"8) It wasn't okay.\\n\", \n",
    "        \"9) It wasn't good.\\n\", \n",
    "        \"10) It wasn't amazing.\\n\"\n",
    "    ]\n",
    "\n",
    "\n",
    "scenarios_list = []\n",
    "for index, domain in enumerate(domains):\n",
    "        for state in states:\n",
    "            for goal in goals:\n",
    "                scenario = \"Scenario:\" + \"\\n\" + domains[domain]['sent_precontext'] + knowledge + domains[domain]['sent_context'] + \"\\n\" + feeling + \"\\n\" + state + \"\\n\" + \"Question:\" + \"\\n\" + goal + \"\\n\" + question + \"\\n\" + \"Options:\" + \"\\n\"\n",
    "\n",
    "                for option in answer_options:\n",
    "                    scenario += option\n",
    "\n",
    "                # for the scenario, randomly sample 10 times from the speaker like\n",
    "                for i in range(10):\n",
    "                    # replace SP with speaker in the speaker list with index\n",
    "                    scenario = scenario.replace(\"SP\", random.choice(names))\n",
    "\n",
    "                    # replace LS with speaker in the speaker list with index\n",
    "                    scenario = scenario.replace(\"LS\", random.choice(names))\n",
    "\n",
    "                    # replace BB with the BB\n",
    "                    scenario = scenario.replace(\"BB\", domains[domain]['BB'])\n",
    "\n",
    "                    scenarios_list.append(scenario)\n",
    "                     \n",
    "                # # replace SP with speaker in the speaker list with index\n",
    "                # scenario = scenario.replace(\"SP\", speakers[index][0])\n",
    "\n",
    "                # # replace LS with speaker in the speaker list with index\n",
    "                # scenario = scenario.replace(\"LS\", speakers[index][1])\n",
    "\n",
    "                # # replace BB with the BB\n",
    "                # scenario = scenario.replace(\"BB\", domains[domain]['BB'])\n",
    "\n",
    "                # scenarios_list.append(scenario)\n",
    "\n",
    "# save scenarios_list to a csv file\n",
    "df = pd.DataFrame(scenarios_list)\n",
    "df.to_csv(\"../data/scenarios_utterance_production_multi_choice_format_different_names.csv\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_options = [\n",
    "        \"1) It was terrible.\\n\", \n",
    "        \"2) It was bad.\\n\", \n",
    "        \"3) It was okay.\\n\", \n",
    "        \"4) It was good.\\n\", \n",
    "        \"5) It was amazing.\\n\",\n",
    "        \"6) It wasn't terrible.\\n\", \n",
    "        \"7) It wasn't bad.\\n\", \n",
    "        \"8) It wasn't okay.\\n\", \n",
    "        \"9) It wasn't good.\\n\", \n",
    "        \"10) It wasn't amazing.\\n\"\n",
    "    ]\n",
    "\n",
    "\"You are the third person in the scenario named Tom, what do you think that Stephan would be most likely to say if Stephan wanted to BOTH make Lucy feel good AND give accurate and informative feedback?\"\n",
    "\n",
    "question = \"SP would be most likely to say \"\n",
    "\n",
    "goals = [\n",
    "        \"if SP wanted to BOTH make LS feel good AND give accurate and informative feedback?\",\n",
    "        \"if SP wanted to give as accurate and informative feedback as possible, but not necessarily make LS feel good?\",\n",
    "        \"if SP wanted to make LS feel good, but not necessarily give informative feedback?\",\n",
    "]\n",
    "\n",
    "scenarios_list = []\n",
    "for index, domain in enumerate(domains):\n",
    "        for state in states:\n",
    "            for goal in goals:\n",
    "                scenario = \"Scenario:\" + \"\\n\" + domains[domain]['sent_precontext'] + knowledge + domains[domain]['sent_context'] + \"\\n\" + feeling + \"\\n\" + state + \"\\n\" + \"Question:\" + \"\\n\" + f\"You are an another person in the scenario named {random.choice(speakers_3)}, what do you think that \" + question + goal + \"\\n\"  + \"\\n\" + \"Options:\" + \"\\n\"\n",
    "\n",
    "                for option in answer_options:\n",
    "                    scenario += option\n",
    "\n",
    "                # replace SP with speaker in the speaker list with index\n",
    "                scenario = scenario.replace(\"SP\", speakers[index][0])\n",
    "\n",
    "                # replace LS with speaker in the speaker list with index\n",
    "                scenario = scenario.replace(\"LS\", speakers[index][1])\n",
    "\n",
    "                # replace BB with the BB\n",
    "                scenario = scenario.replace(\"BB\", domains[domain]['BB'])\n",
    "\n",
    "                scenarios_list.append(scenario)\n",
    "\n",
    "# save scenarios_list to a csv file\n",
    "df = pd.DataFrame(scenarios_list)\n",
    "df.to_csv(\"../data/scenarios_utterance_production_multi_choice_format_different_names.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scenario:\\nImagine that Bob just gave a presentation, but Bob didn\\'t know how good it was. Bob approached John, who knows a lot about giving presentations, and asked \"How was my presentation?\"\\nHere\\'s John\\'s rating of Bob\\'s presentation:\\n1\\nQuestion:\\nYou are an another person in the scenario named Harper, what do you think that John would be most likely to say if John wanted to BOTH make Bob feel good AND give accurate and informative feedback?\\n\\nOptions:\\n1) It was terrible.\\n2) It was bad.\\n3) It was okay.\\n4) It was good.\\n5) It was amazing.\\n6) It wasn\\'t terrible.\\n7) It wasn\\'t bad.\\n8) It wasn\\'t okay.\\n9) It wasn\\'t good.\\n10) It wasn\\'t amazing.\\n'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1950"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scenarios_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_options = [\n",
    "        \"1) It was terrible.\\n\", \n",
    "        \"2) It was bad.\\n\", \n",
    "        \"3) It was okay.\\n\", \n",
    "        \"4) It was good.\\n\", \n",
    "        \"5) It was amazing.\\n\",\n",
    "        \"6) It wasn't terrible.\\n\", \n",
    "        \"7) It wasn't bad.\\n\", \n",
    "        \"8) It wasn't okay.\\n\", \n",
    "        \"9) It wasn't good.\\n\", \n",
    "        \"10) It wasn't amazing.\\n\"\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "scenarios_list = []\n",
    "for index, domain in enumerate(domains):\n",
    "        for state in states_2:\n",
    "            for goal in goals:\n",
    "                scenario = \"Scenario:\" + \"\\n\" + domains[domain]['sent_precontext'] + knowledge + domains[domain]['sent_context'] + \"\\n\" + feeling_2 + \"\\n\" + state + \"\\n\" + \"Question:\" + \"\\n\" + goal + \"\\n\" + question + \"\\n\" + \"Options:\" + \"\\n\"\n",
    "\n",
    "                for option in answer_options:\n",
    "                    scenario += option\n",
    "\n",
    "                # replace SP with speaker in the speaker list with index\n",
    "                scenario = scenario.replace(\"SP\", speakers[index][0])\n",
    "\n",
    "                # replace LS with speaker in the speaker list with index\n",
    "                scenario = scenario.replace(\"LS\", speakers[index][1])\n",
    "\n",
    "                # replace BB with the BB\n",
    "                scenario = scenario.replace(\"BB\", domains[domain]['BB'])\n",
    "\n",
    "                scenarios_list.append(scenario)\n",
    "\n",
    "# save scenarios_list to a csv file\n",
    "df = pd.DataFrame(scenarios_list)\n",
    "df.to_csv(\"../data/scenarios_utterance_production_multi_choice_format_rating_1_5.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_list = []\n",
    "for index, domain in enumerate(domains):\n",
    "        for state in states:\n",
    "            for goal in goals:\n",
    "                scenario = \"Scenario:\" + \"\\n\" + domains[domain]['sent_precontext'] + knowledge + domains[domain]['sent_context'] + \"\\n\" + feeling + \"\\n\" + state + \"\\n\" + \"Question:\" + \"\\n\" + goal + \"\\n\" + question\n",
    "\n",
    "                # replace SP with speaker in the speaker list with index\n",
    "                scenario = scenario.replace(\"SP\", speakers[index][0])\n",
    "\n",
    "                # replace LS with speaker in the speaker list with index\n",
    "                scenario = scenario.replace(\"LS\", speakers[index][1])\n",
    "\n",
    "                # replace BB with the BB\n",
    "                scenario = scenario.replace(\"BB\", domains[domain]['BB'])\n",
    "\n",
    "                scenarios_list.append(scenario)\n",
    "\n",
    "# save scenarios_list to a csv file\n",
    "df = pd.DataFrame(scenarios_list)\n",
    "df.to_csv(\"../data/scenarios_utterance_production_two_set_combo_format.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sets = \"wordset one: ['was', 'wasn't'] \\nwordset two: ['terrible', 'bad', 'okay', 'good', 'amazing']\"\n",
    "\n",
    "scenarios_list = []\n",
    "for index, domain in enumerate(domains):\n",
    "        for state in states:\n",
    "            for goal in goals:\n",
    "                scenario = \"Scenario:\" + \"\\n\" + domains[domain]['sent_precontext'] + knowledge + domains[domain]['sent_context'] + \"\\n\" + feeling + \"\\n\" + state + \"\\n\" + \"Question:\" + \"\\n\" + goal + \"\\n\" + question + \"\\n\" + \"Please answer the question using the combination of the two sets of words shown below (one word from each set):\\n\" +  word_sets + \"\\n\" + \"Please write your answer in the following format:\\nAnswer: <one word for set one, one word for set two>\"\n",
    "\n",
    "                # replace SP with speaker in the speaker list with index\n",
    "                scenario = scenario.replace(\"SP\", speakers[index][0])\n",
    "\n",
    "                # replace LS with speaker in the speaker list with index\n",
    "                scenario = scenario.replace(\"LS\", speakers[index][1])\n",
    "\n",
    "                # replace BB with the BB\n",
    "                scenario = scenario.replace(\"BB\", domains[domain]['BB'])\n",
    "\n",
    "                scenarios_list.append(scenario)\n",
    "\n",
    "# save scenarios_list to a csv file\n",
    "df = pd.DataFrame(scenarios_list)\n",
    "df.to_csv(\"../data/scenarios_utterance_production_two_set_in_scenarios_combo_format.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_list = []\n",
    "for index, domain in enumerate(domains):\n",
    "        for state in states:\n",
    "            for goal in goals:\n",
    "                if goal != \"\":\n",
    "                    scenario = \"Scenario:\" + \"\\n\" + domains[domain]['sent_precontext'] + knowledge + domains[domain]['sent_context'] + \"\\n\" + \"Rating:\" + \"\\n\" + feeling + \"\\n\" + state + \"\\n\" + \"Question:\" + \"\\n\" + goal + \"\\n\" + question\n",
    "                else:\n",
    "                    scenario = \"Scenario:\" + \"\\n\" + domains[domain]['sent_precontext'] + knowledge + domains[domain]['sent_context'] + \"\\n\" + \"Rating:\" + \"\\n\" + feeling + \"\\n\" + state + \"\\n\" + \"Question:\" + \"\\n\" + question\n",
    "                    \n",
    "                # replace SP with speaker in the speaker list with index\n",
    "                scenario = scenario.replace(\"SP\", speakers[index][0])\n",
    "\n",
    "                # replace LS with speaker in the speaker list with index\n",
    "                scenario = scenario.replace(\"LS\", speakers[index][1])\n",
    "\n",
    "                # replace BB with the BB\n",
    "                scenario = scenario.replace(\"BB\", domains[domain]['BB'])\n",
    "\n",
    "                scenarios_list.append(scenario)\n",
    "\n",
    "# save scenarios_list to a csv file\n",
    "df = pd.DataFrame(scenarios_list)\n",
    "df.to_csv(\"../data/scenarios_utterance_production_free_response_format.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_options = [\n",
    "        \"1) It was terrible.\\n\", \n",
    "        \"2) It was bad.\\n\", \n",
    "        \"3) It was good.\\n\", \n",
    "        \"4) It was amazing.\\n\",\n",
    "        \"5) It wasn't terrible.\\n\", \n",
    "        \"6) It wasn't okay.\\n\", \n",
    "        \"7) It wasn't good.\\n\", \n",
    "        \"8) It wasn't amazing.\\n\"\n",
    "    ]\n",
    "\n",
    "goals = [\n",
    "        \"both: If SP wanted to BOTH make LS feel good AND give accurate and informative feedback,\",\n",
    "        \"informative: If SP wanted to give as accurate and informative feedback as possible, but not necessarily make LS feel good,\",\n",
    "        \"social: If SP wanted to make LS feel good, but not necessarily give informative feedback,\",\n",
    "]\n",
    "\n",
    "scenarios_list = []\n",
    "for index, domain in enumerate(domains):\n",
    "        for state in states:\n",
    "            for goal in goals:\n",
    "                scenario = \"Scenario:\" + \"\\n\" + domains[domain]['sent_precontext'] + knowledge + domains[domain]['sent_context'] + \"\\n\" + feeling + \"\\n\" + state + \"\\n\" + \"Question:\" + \"\\n\" + goal + \"\\n\" + question + \"\\n\" + \"Options:\" + \"\\n\"\n",
    "\n",
    "                for option in answer_options:\n",
    "                    scenario += option\n",
    "\n",
    "                # replace SP with speaker in the speaker list with index\n",
    "                scenario = scenario.replace(\"SP\", speakers[index][0])\n",
    "\n",
    "                # replace LS with speaker in the speaker list with index\n",
    "                scenario = scenario.replace(\"LS\", speakers[index][1])\n",
    "\n",
    "                # replace BB with the BB\n",
    "                scenario = scenario.replace(\"BB\", domains[domain]['BB'])\n",
    "\n",
    "                scenarios_list.append(scenario)\n",
    "\n",
    "# save scenarios_list to a csv file\n",
    "df = pd.DataFrame(scenarios_list)\n",
    "df.to_csv(\"../data/scenarios_utterance_production_for_evaluation.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_options = [\n",
    "        \"1) It was terrible.\\n\", \n",
    "        \"2) It was bad.\\n\", \n",
    "        \"3) It was okay.\\n\", \n",
    "        \"4) It was good.\\n\", \n",
    "        \"5) It was amazing.\\n\",\n",
    "        \"6) It wasn't terrible.\\n\", \n",
    "        \"7) It wasn't bad.\\n\", \n",
    "        \"8) It wasn't okay.\\n\", \n",
    "        \"9) It wasn't good.\\n\", \n",
    "        \"10) It wasn't amazing.\\n\"\n",
    "    ]\n",
    "\n",
    "goals = [\n",
    "        \"both: If SP wanted to BOTH make LS feel good AND give accurate and informative feedback,\",\n",
    "        \"informative: If SP wanted to give as accurate and informative feedback as possible, but not necessarily make LS feel good,\",\n",
    "        \"social: If SP wanted to make LS feel good, but not necessarily give informative feedback,\",\n",
    "        \"default:\"\n",
    "]\n",
    "\n",
    "scenarios_list = []\n",
    "for index, domain in enumerate(domains):\n",
    "        for state in states:\n",
    "            for goal in goals:\n",
    "                if goal == \"default:\":\n",
    "                    scenario = \"Scenario:\" + \"\\n\" + domains[domain]['sent_precontext'] + knowledge + domains[domain]['sent_context'] + \"\\n\" + feeling + \"\\n\" + state + \"\\n\" + \"Question:\" + \"\\n\" + goal + \"\\n\" + question + \"\\n\" + \"Options:\" + \"\\n\"\n",
    "                else:\n",
    "                     continue\n",
    "                for option in answer_options:\n",
    "                    scenario += option\n",
    "\n",
    "                # replace SP with speaker in the speaker list with index\n",
    "                scenario = scenario.replace(\"SP\", speakers[index][0])\n",
    "\n",
    "                # replace LS with speaker in the speaker list with index\n",
    "                scenario = scenario.replace(\"LS\", speakers[index][1])\n",
    "\n",
    "                # replace BB with the BB\n",
    "                scenario = scenario.replace(\"BB\", domains[domain]['BB'])\n",
    "\n",
    "                scenarios_list.append(scenario)\n",
    "\n",
    "# save scenarios_list to a csv file\n",
    "df = pd.DataFrame(scenarios_list)\n",
    "df.to_csv(\"../data/scenarios_utterance_production_for_evaluation_default.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_utterance_production_multi_choice_format = pd.read_csv(\"../data/scenarios_utterance_production_multi_choice_format.csv\", header=None)\n",
    "\n",
    "# to list\n",
    "scenarios_utterance_production_multi_choice_format = scenarios_utterance_production_multi_choice_format[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13*5*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13*5*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from pandas) (2.9.0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached pandas-2.2.2-cp312-cp312-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.26.4 pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.2.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Using cached PyYAML-6.0.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached SQLAlchemy-2.0.30-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Using cached aiohttp-3.9.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.5 kB)\n",
      "Collecting langchain-core<0.3.0,>=0.2.0 (from langchain)\n",
      "  Downloading langchain_core-0.2.4-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.74-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain) (1.26.4)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Downloading pydantic-2.7.3-py3-none-any.whl.metadata (108 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m651.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting requests<3,>=2 (from langchain)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.4.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.0.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.9.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.0->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.3.0,>=0.2.0->langchain)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached orjson-3.10.3-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (49 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.18.4 (from pydantic<3,>=1->langchain)\n",
      "  Downloading pydantic_core-2.18.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (4.12.1)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Downloading charset_normalizer-3.3.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Downloading certifi-2024.6.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain)\n",
      "  Using cached jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading langchain-0.2.2-py3-none-any.whl (973 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.6/973.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached aiohttp-3.9.5-cp312-cp312-macosx_11_0_arm64.whl (392 kB)\n",
      "Downloading langchain_core-0.2.4-py3-none-any.whl (310 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.4/310.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n",
      "Downloading langsmith-0.1.74-py3-none-any.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.8/124.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.7.3-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.6/409.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.18.4-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached PyYAML-6.0.1-cp312-cp312-macosx_11_0_arm64.whl (165 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached SQLAlchemy-2.0.30-cp312-cp312-macosx_11_0_arm64.whl (2.1 MB)\n",
      "Using cached tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Downloading certifi-2024.6.2-py3-none-any.whl (164 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.4/164.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.3.2-cp312-cp312-macosx_11_0_arm64.whl (119 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached frozenlist-1.4.1-cp312-cp312-macosx_11_0_arm64.whl (51 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached multidict-6.0.5-cp312-cp312-macosx_11_0_arm64.whl (29 kB)\n",
      "Using cached orjson-3.10.3-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (253 kB)\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Using cached yarl-1.9.4-cp312-cp312-macosx_11_0_arm64.whl (79 kB)\n",
      "Using cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Installing collected packages: urllib3, tenacity, SQLAlchemy, PyYAML, pydantic-core, packaging, orjson, multidict, jsonpointer, idna, frozenlist, charset-normalizer, certifi, attrs, annotated-types, yarl, requests, pydantic, jsonpatch, aiosignal, langsmith, aiohttp, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.0\n",
      "    Uninstalling packaging-24.0:\n",
      "      Successfully uninstalled packaging-24.0\n",
      "Successfully installed PyYAML-6.0.1 SQLAlchemy-2.0.30 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.7.0 attrs-23.2.0 certifi-2024.6.2 charset-normalizer-3.3.2 frozenlist-1.4.1 idna-3.7 jsonpatch-1.33 jsonpointer-2.4 langchain-0.2.2 langchain-core-0.2.4 langchain-text-splitters-0.2.1 langsmith-0.1.74 multidict-6.0.5 orjson-3.10.3 packaging-23.2 pydantic-2.7.3 pydantic-core-2.18.4 requests-2.32.3 tenacity-8.3.0 urllib3-2.2.1 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.66.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.2.3-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain_community) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain_community) (3.9.5)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Using cached dataclasses_json-0.6.6-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain_community) (0.2.2)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain_community) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain_community) (0.1.74)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain_community) (8.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain<0.3.0,>=0.2.0->langchain_community) (0.2.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain<0.3.0,>=0.2.0->langchain_community) (2.7.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain_community) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2024.6.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.12.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain_community) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (2.18.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.2.3-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.6 langchain_community-0.2.3 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_anthropic\n",
      "  Downloading langchain_anthropic-0.1.15-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting anthropic<1,>=0.28.0 (from langchain_anthropic)\n",
      "  Using cached anthropic-0.28.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting defusedxml<0.8.0,>=0.7.1 (from langchain_anthropic)\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.2rc1 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain_anthropic) (0.2.4)\n",
      "Collecting anyio<5,>=3.5.0 (from anthropic<1,>=0.28.0->langchain_anthropic)\n",
      "  Using cached anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from anthropic<1,>=0.28.0->langchain_anthropic)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from anthropic<1,>=0.28.0->langchain_anthropic)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from anthropic<1,>=0.28.0->langchain_anthropic)\n",
      "  Downloading jiter-0.4.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from anthropic<1,>=0.28.0->langchain_anthropic) (2.7.3)\n",
      "Collecting sniffio (from anthropic<1,>=0.28.0->langchain_anthropic)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers>=0.13.0 (from anthropic<1,>=0.28.0->langchain_anthropic)\n",
      "  Using cached tokenizers-0.19.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from anthropic<1,>=0.28.0->langchain_anthropic) (4.12.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.2rc1->langchain_anthropic) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.2rc1->langchain_anthropic) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.66 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.2rc1->langchain_anthropic) (0.1.74)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.2rc1->langchain_anthropic) (23.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.2rc1->langchain_anthropic) (8.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.28.0->langchain_anthropic) (3.7)\n",
      "Requirement already satisfied: certifi in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from httpx<1,>=0.23.0->anthropic<1,>=0.28.0->langchain_anthropic) (2024.6.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->anthropic<1,>=0.28.0->langchain_anthropic)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<1,>=0.28.0->langchain_anthropic)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2rc1->langchain_anthropic) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2.2rc1->langchain_anthropic) (3.10.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2.2rc1->langchain_anthropic) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic<1,>=0.28.0->langchain_anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic<1,>=0.28.0->langchain_anthropic) (2.18.4)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.0->anthropic<1,>=0.28.0->langchain_anthropic)\n",
      "  Downloading huggingface_hub-0.23.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.28.0->langchain_anthropic)\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.28.0->langchain_anthropic)\n",
      "  Downloading fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.28.0->langchain_anthropic) (4.66.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2.2rc1->langchain_anthropic) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2.2rc1->langchain_anthropic) (2.2.1)\n",
      "Downloading langchain_anthropic-0.1.15-py3-none-any.whl (16 kB)\n",
      "Using cached anthropic-0.28.0-py3-none-any.whl (862 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Using cached anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Downloading jiter-0.4.1-cp312-cp312-macosx_11_0_arm64.whl (311 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tokenizers-0.19.1-cp312-cp312-macosx_11_0_arm64.whl (2.4 MB)\n",
      "Downloading huggingface_hub-0.23.3-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.7/401.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.9/176.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: sniffio, jiter, h11, fsspec, filelock, distro, defusedxml, huggingface-hub, httpcore, anyio, tokenizers, httpx, anthropic, langchain_anthropic\n",
      "Successfully installed anthropic-0.28.0 anyio-4.4.0 defusedxml-0.7.1 distro-1.9.0 filelock-3.14.0 fsspec-2024.6.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 huggingface-hub-0.23.3 jiter-0.4.1 langchain_anthropic-0.1.15 sniffio-1.3.1 tokenizers-0.19.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.31.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from openai) (2.7.3)\n",
      "Requirement already satisfied: sniffio in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from openai) (4.12.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
      "Downloading openai-1.31.1-py3-none-any.whl (324 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.1/324.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "Successfully installed openai-1.31.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.2 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain-openai) (0.2.4)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.26.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain-openai) (1.31.1)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.7.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.66 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (0.1.74)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (2.7.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (8.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.12.1)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Downloading regex-2024.5.15-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain-openai) (3.7)\n",
      "Requirement already satisfied: certifi in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain-openai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2.2->langchain-openai) (3.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain-openai) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/haoranzhao/enter/envs/pragmatic_production/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.1)\n",
      "Downloading langchain_openai-0.1.8-py3-none-any.whl (38 kB)\n",
      "Downloading tiktoken-0.7.0-cp312-cp312-macosx_11_0_arm64.whl (906 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.7/906.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.15-cp312-cp312-macosx_11_0_arm64.whl (278 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.5/278.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, tiktoken, langchain-openai\n",
      "Successfully installed langchain-openai-0.1.8 regex-2024.5.15 tiktoken-0.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
